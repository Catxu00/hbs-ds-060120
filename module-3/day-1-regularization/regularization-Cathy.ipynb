{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge & Lasso & Regularization\n",
    "\n",
    "## Objectives \n",
    "<a name=\"objectives\"></a>\n",
    "\n",
    "- List methods other than r-squared to assess model fit\n",
    "\n",
    "- Describe regularization's role in regression\n",
    "\n",
    "- Summarize the difference between L1 and L2 norms\n",
    "\n",
    "- Understand the effect of hyper-parameter $\\alpha$ in Ridge and Lasso.\n",
    "\n",
    "- Compare and contrast between Lasso-Ridge-Linear models.\n",
    "\n",
    "- Apply Lasso and Ridge with sklearn and understand the parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Review \n",
    "## Review Linear Regression once again:\n",
    "![imune](https://media3.giphy.com/media/l4FGBBs6fjtZXzXCE/giphy.gif?cid=ecf05e47dbb74b8bcd3cf3aafbc86e24452503799b466084&rid=giphy.gif)\n",
    "\n",
    "\n",
    "__Linear Model__\n",
    "\n",
    "\n",
    "$$ Y = w_{0} + w_{1}X_1 + w_{2}X_{2} + \\cdots + w_{p}X_{p} + \\varepsilon $$\n",
    "\n",
    " - We train model to understand the paramaters $w_{i}$ \n",
    " \n",
    " - Use linear algebra or gradient descent to find parameters to minimize:\n",
    " \n",
    " Note that the predictions are given by:\n",
    " \n",
    " $$ \\hat{y}_{i} =  w_{0} + w_{1}X_{i1} + w_{2}X_{i2} + \\cdots + w_{p}X_{i_p}$$\n",
    " \n",
    " Therefore individual errors are given by:\n",
    " \n",
    " $$ e_{i} = y_{i} - \\hat{y}_{i} $$\n",
    " \n",
    " As a result, the residual sum of squares can be expressed as:\n",
    " \n",
    " $$ RSS(\\boldsymbol{w}) = \\sum\\limits_{i=0}^{N} e_{i}^{2}$$\n",
    " \n",
    " \n",
    " \n",
    " $$ J(\\boldsymbol{w}) = \\sum\\limits_{i=0}^{N} (y_{i} - w_{0} - w_{1}X_{i1} - w_{2}X_{i2} - \\cdots - w_{p}X_{i_p})^{2} $$\n",
    " \n",
    " And this equation can be written in short hand as:\n",
    " \n",
    " $$ J(\\boldsymbol{w}) = \\rvert \\boldsymbol{y} - X \\boldsymbol{w} \\rvert^{2} $$\n",
    " \n",
    " or with betas as we are used to seeing them:\n",
    " \n",
    " $$ \\text{cost_function}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(b_jx_{ij} + b))^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What methods or metrics have you learned to assess model fit?\n",
    "\n",
    "\n",
    "## Another Question: How do those metrics feel about adding more variables to the model?\n",
    "\n",
    "![schitts](https://media1.giphy.com/media/fXtGlVSI2ZB2E1JO0b/giphy.gif?cid=ecf05e47f55093929090866ffd59873c647521e25e164830&rid=giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "<a name=\"review\"></a>\n",
    "\n",
    "\n",
    "\n",
    "[__Overfitting - Underfitting__](https://github.com/gokererdogan/JaverianaMLCourse/blob/master/Lectures/05.pdf)\n",
    "\n",
    "<img src=\"underfitting_overfitting.png\" alt=\"Bias-Variance\" style=\"width: 500px;\"/>\n",
    "\n",
    "[__Bias - Variance Trade-Off__](http://scott.fortmann-roe.com/docs/BiasVariance.html)\n",
    "\n",
    "<img src=\"bias_variance_trade_off.png\" alt=\"Bias-Variance\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Tools:\n",
    "- AIC & BIC to compare models\n",
    "- Regularization to produce a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: AIC & BIC\n",
    "## Calculating AIC and BIC \n",
    "AIC and BIC are information criteria for evaluating model performance. These measures compute the goodness of fit with the estimated parameters, but apply a penalty function on the number of parameters in the model.\n",
    "\n",
    "\n",
    "The BIC is also known as the _Schwarz information criterion (abrv. SIC)_ or the Schwarz-Bayesian information criteria. The AIC is also known as the Akaike information criterion. Both criterion were developed in the 1970s.\n",
    "\n",
    "- AIC is defined as: $2k - 2log(L)$\n",
    "- BIC is defined as: $klog(n) - 2log(L)$  \n",
    "\n",
    "$n$ = sample size <br>\n",
    "$k$ = variables in model <br>\n",
    "$L$ = log of sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def aic(y, y_pred, k):\n",
    "    resid = y - y_pred\n",
    "    sse = (resid**2).sum()\n",
    "    AIC = 2*k - 2*np.log(sse)\n",
    "    \n",
    "    return AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bic(y, y_pred, k, n):\n",
    "    resid = y - y_pred\n",
    "    sse = (resid**2).sum()\n",
    "    BIC = np.log(n) + n*np.log(sse/n)\n",
    "    \n",
    "    return BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIC & BIC in comparsion\n",
    "\n",
    "Both AIC and BIC are only useful in comparing the performance of two different model specifications and **cannot** be used on their own. \n",
    "\n",
    "_**Lower**_ AIC and BIC are better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Regularization\n",
    "\n",
    "## Regularization Techniques\n",
    "\n",
    "\n",
    "- Why?\n",
    "\n",
    "    - Reduces complexity\n",
    "    \n",
    "    - Reduce the chance of overfitting.\n",
    "    \n",
    "    - Reduces model's variance at the expense of introducing small bias\n",
    "    \n",
    "    - Increases model's interprettability.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Ridge regularization (L2 Norm)\n",
    "![ridge](https://media2.giphy.com/media/3Aie9MmJ0klyM/giphy.gif?cid=ecf05e472724cf8b955fe4da2a1050dd8865bec22b629736&rid=giphy.gif)\n",
    "\n",
    "Instead of minimizing $J(w)$ (least squares method), we will minimize:\n",
    "\n",
    "$$ J_{\\alpha}(\\boldsymbol{w}) = J(\\boldsymbol{w}) + \\alpha\\sum_{i=1}^{p} w_{i}^{2} $$\n",
    "\n",
    "Function is in sklearn as [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "\n",
    "The **goal** of ridge regression is to find  the right alpha that best manages multicolinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ridge regression applies a penalizing parameter $\\lambda$ *slope* $^2$, such that a small bias will be introduced to the entire model depending on the value of $\\lambda$, which is called a *hyperparameter*. \n",
    "\n",
    "$$ \\text{cost_function_ridge}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(b_jx_{ij} + b))^2 + \\lambda \\sum_{j=1}^p b_j^2$$\n",
    "\n",
    "The result of applying such a penalizing parameter to the cost function, resulting a different regression model that minimizing the residual sum of square **and** the term $\\lambda \\sum_{j=1}^p b_j^2$. \n",
    "\n",
    "The Ridge regression improves the fit of the original regression line by introducing some bias/changing the slope and intercept of the original line. Recall the way we interpret a regression model Y = mx + b: with every unit increase in x, the outcome y increase by m unit. Therefore, the bigger the coefficient m is, the more the outcome is subjected to changes in predictor x. Ridge regression works by reducing the magnitude of the coefficient m and therefore reducing the effect the predictors have on the outcome. Let's look at a simple example.\n",
    "\n",
    "The ridge regression penalty term contains all of the coefficients squared from the original regression line except for the intercept term. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Lasso regularization (L1 Norm)\n",
    "![lasso](https://media3.giphy.com/media/wRKeX8o1eIxxu/giphy.gif?cid=ecf05e47a70490d9dee94f19dd8876390c0ef88243356922&rid=giphy.gif)\n",
    "\n",
    "Instead of minimizing $J(\\boldsymbol{\\omega})$, we will minimize:\n",
    "\n",
    "$$ J_{\\alpha}(\\boldsymbol{w}) = J(\\boldsymbol{w}) + \\alpha\\sum_{i=1}^{p}| w_{i} | $$\n",
    "\n",
    "Function in skelarn as [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "\n",
    "The **goal** of lasso regression is to obtain the subset of predictors and increase model interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression is very similar to Ridge regression except for one difference - the penalty term is not squared but the absolute values of the coefficients muliplied by lambda, expressed by:\n",
    "\n",
    "$$ \\text{cost_function_lasso}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(b_jx_{ij} + b))^2 + \\lambda \\sum_{j=1}^p \\mid b_j \\mid$$\n",
    "\n",
    "The biggest difference in Ridge and Lasso is that Lasso simultaneously performs variable selection: some coefficients are shrunk to 0, rendering them nonexistence in the original regression model. Therefore, Lasso regression performs very well when you have higher dimensional dataset where some predictors are useless; whereas Ridge works best when all the predictors are needed. \n",
    "\n",
    "<img src=\"https://media.giphy.com/media/AWeYSE0qgpk76/giphy.gif\" width= \"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# implementation \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = sns.load_dataset('mpg')\n",
    "\n",
    "#data = pd.read_csv(\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-2-24-09-ridge-and-lasso-regression/master/auto-mpg.csv\") \n",
    "data = data.sample(50, random_state=123)\n",
    "y = data[[\"mpg\"]]\n",
    "X = data.drop([\"mpg\", \"name\", \"origin\"], axis=1)\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "transformed = scale.fit_transform(X)\n",
    "X = pd.DataFrame(transformed, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2391</td>\n",
       "      <td>15.5</td>\n",
       "      <td>74</td>\n",
       "      <td>japan</td>\n",
       "      <td>subaru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>383.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4955</td>\n",
       "      <td>11.5</td>\n",
       "      <td>71</td>\n",
       "      <td>usa</td>\n",
       "      <td>dodge monaco (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2868</td>\n",
       "      <td>15.5</td>\n",
       "      <td>73</td>\n",
       "      <td>europe</td>\n",
       "      <td>volvo 144ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen super beetle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1925</td>\n",
       "      <td>14.0</td>\n",
       "      <td>79</td>\n",
       "      <td>europe</td>\n",
       "      <td>vw rabbit custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>18.1</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3205</td>\n",
       "      <td>11.2</td>\n",
       "      <td>78</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford futura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>35.0</td>\n",
       "      <td>4</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1613</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71</td>\n",
       "      <td>japan</td>\n",
       "      <td>datsun 1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>27.2</td>\n",
       "      <td>4</td>\n",
       "      <td>141.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3190</td>\n",
       "      <td>24.8</td>\n",
       "      <td>79</td>\n",
       "      <td>europe</td>\n",
       "      <td>peugeot 504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>41.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2144</td>\n",
       "      <td>14.7</td>\n",
       "      <td>80</td>\n",
       "      <td>europe</td>\n",
       "      <td>vw rabbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4464</td>\n",
       "      <td>12.0</td>\n",
       "      <td>73</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet caprice classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2223</td>\n",
       "      <td>16.5</td>\n",
       "      <td>75</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen dasher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>38.0</td>\n",
       "      <td>4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2125</td>\n",
       "      <td>14.7</td>\n",
       "      <td>82</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth horizon miser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>38.0</td>\n",
       "      <td>6</td>\n",
       "      <td>262.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3015</td>\n",
       "      <td>17.0</td>\n",
       "      <td>82</td>\n",
       "      <td>usa</td>\n",
       "      <td>oldsmobile cutlass ciera (diesel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2634</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71</td>\n",
       "      <td>usa</td>\n",
       "      <td>amc gremlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>20.0</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3651</td>\n",
       "      <td>17.7</td>\n",
       "      <td>76</td>\n",
       "      <td>usa</td>\n",
       "      <td>dodge aspen se</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>16.2</td>\n",
       "      <td>6</td>\n",
       "      <td>163.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>3410</td>\n",
       "      <td>15.8</td>\n",
       "      <td>78</td>\n",
       "      <td>europe</td>\n",
       "      <td>peugeot 604sl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>15.5</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3962</td>\n",
       "      <td>13.9</td>\n",
       "      <td>76</td>\n",
       "      <td>usa</td>\n",
       "      <td>amc matador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6</td>\n",
       "      <td>156.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2930</td>\n",
       "      <td>15.5</td>\n",
       "      <td>76</td>\n",
       "      <td>japan</td>\n",
       "      <td>toyota mark ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4096</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth fury iii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>390.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3850</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>amc ambassador dpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>35.1</td>\n",
       "      <td>4</td>\n",
       "      <td>81.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1760</td>\n",
       "      <td>16.1</td>\n",
       "      <td>81</td>\n",
       "      <td>japan</td>\n",
       "      <td>honda civic 1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>18.5</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3940</td>\n",
       "      <td>13.0</td>\n",
       "      <td>79</td>\n",
       "      <td>usa</td>\n",
       "      <td>chrysler lebaron town @ country (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>96.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2189</td>\n",
       "      <td>18.0</td>\n",
       "      <td>72</td>\n",
       "      <td>europe</td>\n",
       "      <td>renault 12 (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1963</td>\n",
       "      <td>15.5</td>\n",
       "      <td>74</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen dasher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth duster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford mustang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>340.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>3609</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth 'cuda 340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>35.0</td>\n",
       "      <td>4</td>\n",
       "      <td>122.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>15.1</td>\n",
       "      <td>80</td>\n",
       "      <td>europe</td>\n",
       "      <td>triumph tr7 coupe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1937</td>\n",
       "      <td>14.0</td>\n",
       "      <td>75</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen rabbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>21.5</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>12.8</td>\n",
       "      <td>77</td>\n",
       "      <td>europe</td>\n",
       "      <td>bmw 320i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2592</td>\n",
       "      <td>18.5</td>\n",
       "      <td>75</td>\n",
       "      <td>usa</td>\n",
       "      <td>pontiac astro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>23.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2904</td>\n",
       "      <td>16.0</td>\n",
       "      <td>73</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth duster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>22.3</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2890</td>\n",
       "      <td>17.3</td>\n",
       "      <td>79</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford fairmont 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>14.5</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4215</td>\n",
       "      <td>12.8</td>\n",
       "      <td>76</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford gran torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>28.1</td>\n",
       "      <td>4</td>\n",
       "      <td>141.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3230</td>\n",
       "      <td>20.4</td>\n",
       "      <td>81</td>\n",
       "      <td>europe</td>\n",
       "      <td>peugeot 505s turbo diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>24.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2164</td>\n",
       "      <td>22.1</td>\n",
       "      <td>76</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet woody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>181.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2945</td>\n",
       "      <td>16.4</td>\n",
       "      <td>82</td>\n",
       "      <td>usa</td>\n",
       "      <td>buick century limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>37.0</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>19.4</td>\n",
       "      <td>81</td>\n",
       "      <td>japan</td>\n",
       "      <td>datsun 210 mpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4077</td>\n",
       "      <td>14.0</td>\n",
       "      <td>72</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth satellite custom (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>35.7</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1915</td>\n",
       "      <td>14.4</td>\n",
       "      <td>79</td>\n",
       "      <td>usa</td>\n",
       "      <td>dodge colt hatchback custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3399</td>\n",
       "      <td>11.0</td>\n",
       "      <td>73</td>\n",
       "      <td>usa</td>\n",
       "      <td>dodge dart custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>37.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>18.2</td>\n",
       "      <td>82</td>\n",
       "      <td>japan</td>\n",
       "      <td>mazda glc custom l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>30.0</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2155</td>\n",
       "      <td>16.5</td>\n",
       "      <td>78</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet chevette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>34.2</td>\n",
       "      <td>4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2200</td>\n",
       "      <td>13.2</td>\n",
       "      <td>79</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth horizon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2108</td>\n",
       "      <td>15.5</td>\n",
       "      <td>74</td>\n",
       "      <td>europe</td>\n",
       "      <td>fiat 128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3302</td>\n",
       "      <td>15.5</td>\n",
       "      <td>71</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford torino 500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>4657</td>\n",
       "      <td>13.5</td>\n",
       "      <td>75</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>115.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2694</td>\n",
       "      <td>15.0</td>\n",
       "      <td>75</td>\n",
       "      <td>europe</td>\n",
       "      <td>audi 100ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2585</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "      <td>usa</td>\n",
       "      <td>chrysler lebaron medallion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>32.8</td>\n",
       "      <td>4</td>\n",
       "      <td>78.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>19.4</td>\n",
       "      <td>78</td>\n",
       "      <td>japan</td>\n",
       "      <td>mazda glc deluxe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "150  26.0          4         108.0        93.0    2391          15.5   \n",
       "42   12.0          8         383.0       180.0    4955          11.5   \n",
       "120  19.0          4         121.0       112.0    2868          15.5   \n",
       "102  26.0          4          97.0        46.0    1950          21.0   \n",
       "293  31.9          4          89.0        71.0    1925          14.0   \n",
       "264  18.1          8         302.0       139.0    3205          11.2   \n",
       "54   35.0          4          72.0        69.0    1613          18.0   \n",
       "299  27.2          4         141.0        71.0    3190          24.8   \n",
       "309  41.5          4          98.0        76.0    2144          14.7   \n",
       "91   13.0          8         400.0       150.0    4464          12.0   \n",
       "172  25.0          4          90.0        71.0    2223          16.5   \n",
       "378  38.0          4         105.0        63.0    2125          14.7   \n",
       "387  38.0          6         262.0        85.0    3015          17.0   \n",
       "33   19.0          6         232.0       100.0    2634          13.0   \n",
       "199  20.0          6         225.0       100.0    3651          17.7   \n",
       "277  16.2          6         163.0       133.0    3410          15.8   \n",
       "189  15.5          8         304.0       120.0    3962          13.9   \n",
       "210  19.0          6         156.0       108.0    2930          15.5   \n",
       "41   14.0          8         318.0       150.0    4096          13.0   \n",
       "9    15.0          8         390.0       190.0    3850           8.5   \n",
       "345  35.1          4          81.0        60.0    1760          16.1   \n",
       "292  18.5          8         360.0       150.0    3940          13.0   \n",
       "79   26.0          4          96.0        69.0    2189          18.0   \n",
       "142  26.0          4          79.0        67.0    1963          15.5   \n",
       "15   22.0          6         198.0        95.0    2833          15.5   \n",
       "48   18.0          6         250.0        88.0    3139          14.5   \n",
       "11   14.0          8         340.0       160.0    3609           8.0   \n",
       "335  35.0          4         122.0        88.0    2500          15.1   \n",
       "175  29.0          4          90.0        70.0    1937          14.0   \n",
       "242  21.5          4         121.0       110.0    2600          12.8   \n",
       "170  23.0          4         140.0        78.0    2592          18.5   \n",
       "101  23.0          6         198.0        95.0    2904          16.0   \n",
       "282  22.3          4         140.0        88.0    2890          17.3   \n",
       "190  14.5          8         351.0       152.0    4215          12.8   \n",
       "359  28.1          4         141.0        80.0    3230          20.4   \n",
       "196  24.5          4          98.0        60.0    2164          22.1   \n",
       "386  25.0          6         181.0       110.0    2945          16.4   \n",
       "347  37.0          4          85.0        65.0    1975          19.4   \n",
       "75   14.0          8         318.0       150.0    4077          14.0   \n",
       "295  35.7          4          98.0        80.0    1915          14.4   \n",
       "121  15.0          8         318.0       150.0    3399          11.0   \n",
       "376  37.0          4          91.0        68.0    2025          18.2   \n",
       "266  30.0          4          98.0        68.0    2155          16.5   \n",
       "301  34.2          4         105.0        70.0    2200          13.2   \n",
       "147  24.0          4          90.0        75.0    2108          15.5   \n",
       "36   19.0          6         250.0        88.0    3302          15.5   \n",
       "159  14.0          8         351.0       148.0    4657          13.5   \n",
       "177  23.0          4         115.0        95.0    2694          15.0   \n",
       "388  26.0          4         156.0        92.0    2585          14.5   \n",
       "246  32.8          4          78.0        52.0    1985          19.4   \n",
       "\n",
       "     model_year  origin                                  name  \n",
       "150          74   japan                                subaru  \n",
       "42           71     usa                     dodge monaco (sw)  \n",
       "120          73  europe                           volvo 144ea  \n",
       "102          73  europe               volkswagen super beetle  \n",
       "293          79  europe                      vw rabbit custom  \n",
       "264          78     usa                           ford futura  \n",
       "54           71   japan                           datsun 1200  \n",
       "299          79  europe                           peugeot 504  \n",
       "309          80  europe                             vw rabbit  \n",
       "91           73     usa             chevrolet caprice classic  \n",
       "172          75  europe                     volkswagen dasher  \n",
       "378          82     usa                plymouth horizon miser  \n",
       "387          82     usa     oldsmobile cutlass ciera (diesel)  \n",
       "33           71     usa                           amc gremlin  \n",
       "199          76     usa                        dodge aspen se  \n",
       "277          78  europe                         peugeot 604sl  \n",
       "189          76     usa                           amc matador  \n",
       "210          76   japan                        toyota mark ii  \n",
       "41           71     usa                     plymouth fury iii  \n",
       "9            70     usa                    amc ambassador dpl  \n",
       "345          81   japan                      honda civic 1300  \n",
       "292          79     usa  chrysler lebaron town @ country (sw)  \n",
       "79           72  europe                       renault 12 (sw)  \n",
       "142          74  europe                     volkswagen dasher  \n",
       "15           70     usa                       plymouth duster  \n",
       "48           71     usa                          ford mustang  \n",
       "11           70     usa                    plymouth 'cuda 340  \n",
       "335          80  europe                     triumph tr7 coupe  \n",
       "175          75  europe                     volkswagen rabbit  \n",
       "242          77  europe                              bmw 320i  \n",
       "170          75     usa                         pontiac astro  \n",
       "101          73     usa                       plymouth duster  \n",
       "282          79     usa                       ford fairmont 4  \n",
       "190          76     usa                      ford gran torino  \n",
       "359          81  europe             peugeot 505s turbo diesel  \n",
       "196          76     usa                       chevrolet woody  \n",
       "386          82     usa                 buick century limited  \n",
       "347          81   japan                        datsun 210 mpg  \n",
       "75           72     usa        plymouth satellite custom (sw)  \n",
       "295          79     usa           dodge colt hatchback custom  \n",
       "121          73     usa                     dodge dart custom  \n",
       "376          82   japan                    mazda glc custom l  \n",
       "266          78     usa                    chevrolet chevette  \n",
       "301          79     usa                      plymouth horizon  \n",
       "147          74  europe                              fiat 128  \n",
       "36           71     usa                       ford torino 500  \n",
       "159          75     usa                              ford ltd  \n",
       "177          75  europe                            audi 100ls  \n",
       "388          82     usa            chrysler lebaron medallion  \n",
       "246          78   japan                      mazda glc deluxe  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform test train split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# Build a Ridge, Lasso and regular linear regression model. \n",
    "# Note how in scikit learn, the regularization parameter is denoted by alpha (and not lambda)\n",
    "ridge = Ridge(alpha=0.5)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "lasso = Lasso(alpha=0.5)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpenalized Linear Regression Coefficients are:[[ -9.03445885  18.75002593  -5.65538315 -24.43537253  -0.61679471\n",
      "   11.30827559]]\n",
      "Unpenalized Linear Regression Intercept:[26.94980584]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unpenalized Linear Regression Coefficients are:{}\".format(lin.coef_))\n",
    "print(\"Unpenalized Linear Regression Intercept:{}\".format(lin.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Coefficients are:[-8.32620744 -0.         -0.         -2.55763186  0.          6.32285785]\n",
      "Lasso Linear Regression Intercept:[24.93079318]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso Regression Coefficients are:{}\".format(lasso.coef_))\n",
    "print(\"Lasso Linear Regression Intercept:{}\".format(lasso.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Coefficients are:[[-3.67791324  0.31588162 -7.1371921  -9.26069234 -1.87920316  9.50205856]]\n",
      "Ridge Linear Regression Intercept:[27.60625095]\n"
     ]
    }
   ],
   "source": [
    "print(\"Ridge Regression Coefficients are:{}\".format(ridge.coef_))\n",
    "print(\"Ridge Linear Regression Intercept:{}\".format(ridge.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "y_h_ridge_train = ridge.predict(X_train)\n",
    "y_h_ridge_test = ridge.predict(X_test)\n",
    "\n",
    "y_h_lasso_train = np.reshape(lasso.predict(X_train),(40,1))\n",
    "y_h_lasso_test = np.reshape(lasso.predict(X_test),(10,1))\n",
    "\n",
    "y_h_lin_train = lin.predict(X_train)\n",
    "y_h_lin_test = lin.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_h_ridge_train.shape)\n",
    "print(y_h_ridge_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_h_lasso_train))\n",
    "print(type(y_h_ridge_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the Residual for Ridge, Lasso, and Unpenalized Regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error Ridge Model mpg    452.491502\n",
      "dtype: float64\n",
      "Test Error Ridge Model mpg    185.922671\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Train Error Lasso Model mpg    737.546132\n",
      "dtype: float64\n",
      "Test Error Lasso Model mpg    249.816914\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Train Error Unpenalized Linear Model mpg    367.35827\n",
      "dtype: float64\n",
      "Test Error Unpenalized Linear Model mpg    191.294048\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# examine the residual sum of sq\n",
    "print('Train Error Ridge Model', np.sum((y_train - y_h_ridge_train)**2))\n",
    "print('Test Error Ridge Model', np.sum((y_test - y_h_ridge_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Lasso Model', np.sum((y_train - y_h_lasso_train)**2))\n",
    "print('Test Error Lasso Model', np.sum((y_test - y_h_lasso_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Unpenalized Linear Model', np.sum((y_train - lin.predict(X_train))**2))\n",
    "print('Test Error Unpenalized Linear Model', np.sum((y_test - lin.predict(X_test))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2c: Crossvalidation to Optimize the Regularization Hyperparameter\n",
    "\n",
    "The regularization strength could sensibly be any nonnegative number, so there's no way to check \"all possible\" values. It's often useful to try several values that are different orders of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [1, 10, 100, 1000, 10000]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    rr = Ridge(alpha=alpha, random_state=42)\n",
    "    # upate the names of your datasets\n",
    "    rr.fit(X_train, y_train)\n",
    "    train_score = rr.score(X_train, y_train)\n",
    "    test_score = cross_val_score(rr, X_test, y_test).mean()\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots()\n",
    "plt.xscale('log')\n",
    "plt.title('Ridge $R^2$ as a function of regularization strength')\n",
    "ax.set_xlabel('Regularization strength $\\lambda$')\n",
    "ax.set_ylabel('$R^2$')\n",
    "ax.plot(alphas, train_scores, label='train')\n",
    "ax.plot(alphas, test_scores, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Practice\n",
    "\n",
    "__Your Turn__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>x0_Chinstrap</th>\n",
       "      <th>x0_Gentoo</th>\n",
       "      <th>x1_Dream</th>\n",
       "      <th>x1_Torgersen</th>\n",
       "      <th>x2_MALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>55.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>43.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>47.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>53.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     culmen_length_mm  culmen_depth_mm  flipper_length_mm  x0_Chinstrap  \\\n",
       "321              55.9             17.0              228.0           0.0   \n",
       "265              43.6             13.9              217.0           0.0   \n",
       "36               38.8             20.0              190.0           0.0   \n",
       "308              47.5             14.0              212.0           0.0   \n",
       "191              53.5             19.9              205.0           1.0   \n",
       "\n",
       "     x0_Gentoo  x1_Dream  x1_Torgersen  x2_MALE  \n",
       "321        1.0       0.0           0.0      1.0  \n",
       "265        1.0       0.0           0.0      0.0  \n",
       "36         0.0       1.0           0.0      1.0  \n",
       "308        1.0       0.0           0.0      0.0  \n",
       "191        0.0       1.0           0.0      1.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "birds = sns.load_dataset('penguins')\n",
    "\n",
    "# For simplicity's sake we'll limit our analysis to the numeric columns.\n",
    "\n",
    "# numeric = birds[['culmen_length_mm', 'culmen_depth_mm','flipper_length_mm', 'body_mass_g']]\n",
    "\n",
    "\n",
    "# We'll drop the rows with null values\n",
    "birds = birds.dropna()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(birds.drop('body_mass_g',\n",
    "                                                              axis=1),\n",
    "                                                   birds['body_mass_g'],\n",
    "                                                   random_state=42)\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "dummies = ohe.fit_transform(X_train[['species', 'island', 'sex']])\n",
    "dummies_df = pd.DataFrame(dummies.todense(), columns=ohe.get_feature_names(),\n",
    "                         index=X_train.index)\n",
    "X_train_df = pd.concat([X_train[['culmen_length_mm', 'culmen_depth_mm',\n",
    "                                'flipper_length_mm']], dummies_df], axis=1)\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try at least 3 different model specifications, using polynomials, interaction terms, etc\n",
    "- Group 1: Use AIC and BIC to pick your \"best\" model specification using Linear Regression\n",
    "- Group 2: Use Ridge AND experiement with different values of alpha to find the \"best\" model. Compare MSE in train and test for each model specification.\n",
    "- Group 3: Use Lasso AND experiment with different values of alpha to find the \"best\" model. Compare MSE in train and test for each model specification.\n",
    "- Report your observations.\n",
    "- A graph comparing your findings and suggesting a model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.5)\n",
    "lasso.fit(X_train_df, y_train)\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Coefficients are:[  15.10768488   68.49779406   17.13019293 -228.05639523 1026.73620242\n",
      "    8.66504461  -44.14246672  386.14456129]\n",
      "Lasso Linear Regression Intercept:-1594.5702008510725\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso Regression Coefficients are:{}\".format(lasso.coef_))\n",
    "print(\"Lasso Linear Regression Intercept:{}\".format(lasso.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Summary\n",
    "\n",
    "#### Effect of $\\alpha$ in Lasso and Ridge\n",
    "\n",
    "<img src=\"lasso_effect_of_lambda.png\" alt=\"Lasso-Lambda\" style=\"width: 500px;\"/>\n",
    "\n",
    "<img src=\"ridge_effect_of_lambda.png\" alt=\"Lasso-Lambda\" style=\"width: 500px;\"/>\n",
    "\n",
    "<a name='questions'></a>\n",
    "### Questions\n",
    "\n",
    "\n",
    "\n",
    "Q. Should I do normalization for Lasso or Ridge?\n",
    "\n",
    "A. Yes? Why?\n",
    "\n",
    "Q. When we know that Ridge and Lasso is better than vanilla linear regression?\n",
    "\n",
    "A. High variation in your model --> Colinearity and too many variables.\n",
    "\n",
    "Q. How do we know whether we should choose Lasso or Ridge?\n",
    "\n",
    "A. Most of the time they perform very similar but Lasso has the feature selection property, ridge doesn't have this.\n",
    "\n",
    "Q: How do we choose $\\lambda$?\n",
    "\n",
    "A. [sklearn gridsearch](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) for small models or random grid search for bigger models.\n",
    "\n",
    "#### Appendix\n",
    "<a name='appendix'></a>\n",
    "\n",
    "Here I would like to add some reading material that I found useful while working with the code.\n",
    "\n",
    "\n",
    "-  [On ridge and lasso](https://bradleyboehmke.github.io/HOML/regularized-regression.html)\n",
    "\n",
    "- [pd.get_dummies or OneHotEncoder? - Read second answer](https://stackoverflow.com/questions/36631163/pandas-get-dummies-vs-sklearns-onehotencoder-what-are-the-pros-and-cons)\n",
    "\n",
    "- [On dummy variable trap](https://www.algosome.com/articles/dummy-variable-trap-regression.html)\n",
    "\n",
    "- [sklearn.preprocessing.PolynomialFeatures documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "\n",
    "- [A great notebook on Lasso and Ridge](https://github.com/gokererdogan/JaverianaMLCourse/blob/master/Lectures/05.pdf)\n",
    "\n",
    "- [Another good blog post on Lasso and Ridge](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/)\n",
    "\n",
    "- Learn.co -- Section-28 Lasso-Ridge\n",
    "\n",
    "- [Toward Datascience Article](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)\n",
    "\n",
    "- [ISLR](http://faculty.marshall.usc.edu/gareth-james/ISL/) 2.2.2 The Bias-Variance Trade-off and 6.2 Shrinkage Methods\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Image Sources in order of appearance: \n",
    "- https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html\n",
    "\n",
    "- https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
